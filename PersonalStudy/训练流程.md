### MotionMillion项目训练代码流程

### 原始数据集下载（一部分就行）

[InternRobotics/MotionMillion at main](https://huggingface.co/datasets/InternRobotics/MotionMillion/tree/main)

split.tar.gz、texts.tar.gz、mean_std、motion_272rpr的MotionLLAMA的一部分数据

![image-20250930120604150](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930120604150.png)

![image-20250930120900241](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930120900241.png)

#### 1. 数据处理流程

![image-20250930121236900](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930121236900.png)

![image-20250930121626338](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930121626338.png)

似乎是训练时自动调用的，需要研读

#### 2. 训练流程

目录结构：

![image-20250930120929470](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930120929470.png)

执行训练：

![image-20250930114936605](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930114936605.png)





1. 熟悉这些数据格式（后面需要用这些数据训练我们的PFNN模型,到时候我会让你将数据处理成pfnn的格式）
2. Train Tokenizer(学习他如何利用FSQ对动作编码的，你需要理解并给我讲清楚FSQ的好处，为啥不用VQ-VAE，是你自己的想法，因为他们可能只是为了凑个新的点作为自己的创新点)
3. Train Text-to-Motion model这部分你跑一遍理解一下基于transformer的decoder是怎么运作的
4. 然后你需要对每个数据集的动作类型，处理代码了解清楚，如果他是将不同格式的数据都处理成motionMillion的data representation的话





### 我做了什么：

#### 问题：

![image-20250930184028037](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930184028037.png)

![image-20250930184131755](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930184131755.png)

文件里包含了太多没有下载下来的文件，都修改了一下，只保留MotionGV/folder0/开头的文件





#### 问题：

![image-20250930182934259](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930182934259.png)

![image-20250930185914707](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930185914707.png)

![image-20250930185947597](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930185947597.png)

![image-20250930190036525](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930190036525.png)

![image-20250930190046495](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930190046495.png)





跑着跑着内存就炸了，可能必须得上服务器了

![image-20250930195637901](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930195637901.png)

后续：怀疑是split删改的锅，但是还原后还是出现了内存爆炸的情况，可能确实跑不了？

![image-20250930221533887](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930221533887.png)





### 10/1：任务：

修改脚本获取train tokenizer VQVAE的具体参数

train_tokenizer.py里面会有VQVAE的初始化代码（120行开始net = vqvae.HumanVQVAE(args,...）
然后等它初始化完，调用torch的接口print这个模型参数的大小（trainable parameter的数量）

```python
import torch
import torch.nn as nn

# 假设你有一个模型
model = nn.Sequential(
    nn.Linear(100, 50),
    nn.ReLU(),
    nn.Linear(50, 10)
)

# 方法1.1: 打印每个参数的形状和大小
for name, param in model.named_parameters():
    print(f"{name}: {param.shape} | 参数数量: {param.numel()}")

# 输出:
# 0.weight: torch.Size([50, 100]) | 参数数量: 5000
# 0.bias: torch.Size([50]) | 参数数量: 50
# 2.weight: torch.Size([10, 50]) | 参数数量: 500
# 2.bias: torch.Size([10]) | 参数数量: 10
# 方法1.2: 计算总参数数量
total_params = sum(p.numel() for p in model.parameters())
print(f"总参数量: {total_params:,}")  # 输出: 总参数量: 5,560

# 方法1.3: 计算可训练参数数量（通常与总参数相同，除非冻结了某些层）
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"可训练参数量: {trainable_params:,}")
```

![image-20251002172532530](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251002172532530.png)

输出结果：

```
2025-10-02 17:23:54,728 INFO ==================================================
2025-10-02 17:23:54,728 INFO HumanVQVAE 模型参数信息:
2025-10-02 17:23:54,728 INFO ==================================================
2025-10-02 17:23:54,728 INFO vqvae.encoder.model.1.weight: torch.Size([512, 272, 3]) | 参数数量: 417,792
2025-10-02 17:23:54,728 INFO vqvae.encoder.model.1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.0.weight: torch.Size([512, 512, 4]) | 参数数量: 1,048,576
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.0.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.norm1.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.norm1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.norm2.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.norm2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.conv1.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.conv1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.conv2.weight: torch.Size([512, 512, 1]) | 参数数量: 262,144
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.0.conv2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.norm1.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.norm1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.norm2.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.norm2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.conv1.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.conv1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.conv2.weight: torch.Size([512, 512, 1]) | 参数数量: 262,144
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.1.conv2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.2.norm1.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.2.norm1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.2.norm2.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.2.norm2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.2.conv1.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.2.conv1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,732 INFO vqvae.encoder.model.3.1.model.2.conv2.weight: torch.Size([512, 512, 1]) | 参数数量: 262,144
2025-10-02 17:23:54,732 INFO vqvae.encoder.model.3.1.model.2.conv2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,732 INFO vqvae.encoder.model.4.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,732 INFO vqvae.encoder.model.4.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,732 INFO vqvae.decoder.model.0.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,732 INFO vqvae.decoder.model.0.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,732 INFO vqvae.decoder.model.2.0.model.0.norm1.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.norm1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.norm2.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.norm2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.conv1.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.conv1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.conv2.weight: torch.Size([512, 512, 1]) | 参数数量: 262,144
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.conv2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.1.norm1.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.1.norm1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.1.norm2.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.1.norm2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.1.conv1.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.1.conv1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.1.conv2.weight: torch.Size([512, 512, 1]) | 参数数量: 262,144
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.1.conv2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.2.norm1.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.2.norm1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.0.model.2.norm2.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.0.model.2.norm2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.0.model.2.conv1.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.0.model.2.conv1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.0.model.2.conv2.weight: torch.Size([512, 512, 1]) | 参数数量: 262,144
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.0.model.2.conv2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.2.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.3.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.3.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.5.weight: torch.Size([272, 512, 3]) | 参数数量: 417,792
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.5.bias: torch.Size([272]) | 参数数量: 272
2025-10-02 17:23:54,735 INFO vqvae.quantizer.project_in.weight: torch.Size([6, 512]) | 参数数量: 3,072
2025-10-02 17:23:54,736 INFO vqvae.quantizer.project_in.bias: torch.Size([6]) | 参数数量: 6
2025-10-02 17:23:54,736 INFO vqvae.quantizer.project_out.weight: torch.Size([512, 6]) | 参数数量: 3,072
2025-10-02 17:23:54,736 INFO vqvae.quantizer.project_out.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,736 INFO ==================================================
2025-10-02 17:23:54,736 INFO 总参数量: 11,349,782
2025-10-02 17:23:54,736 INFO 可训练参数量: 11,349,782
2025-10-02 17:23:54,736 INFO ==================================================
2025-10-02 17:23:54,736 INFO 模型参数统计完成，程序结束
```

![image-20251002175911948](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251002175911948.png)

![image-20251002175929632](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251002175929632.png)





### 10/2：继续定位：

问题似乎出在这里，需要进一步看看到底是在做什么：

![image-20251002180828538](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251002180828538.png)

其中一个问题（内存分配问题）应该是手部模型的锅，这里应该用不到，想办法取消掉





### 10/3-4，定位问题，修改参数：

![image-20251005233810119](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005233810119.png)

warm_up部分能跑完了。



### 10/5：训练部分：

修改了训练参数之后warm_up部分没问题了，但还是训练会出现

![屏幕截图 2025-10-05 232509](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-10-05%20232509.png)

#### 尝试一：

在AI的建议下尝试修改代码：

![image-20251005234318581](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005234318581.png)

![image-20251005234232541](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005234232541.png)

![image-20251005234241711](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005234241711.png)

![image-20251005234259295](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005234259295.png)

![image-20251005234310590](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005234310590.png)

出现了这样的问题：

![image-20251005234843224](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005234843224.png)

撤回了更改



#### 尝试二：

![image-20251005235217821](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005235217821.png)

![image-20251006000005432](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006000005432.png)

![image-20251005235907786](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005235907786.png)

还是先撤回问问老师吧





10/6：

注释了可视化相关的代码，还是出现了问题：![image-20251006145731863](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006145731863.png)

![image-20251006145758974](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006145758974.png)

![image-20251006145811726](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006145811726.png)

![image-20251006145820774](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006145820774.png)



#### 10/6：直接注释了对应的代码：

新的问题接踵而至：

![image-20251006153533449](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006153533449.png)

问题是压根就没有current_batch这个变量呀？

是Util缓存的问题？，但是原来的代码没有current_batch这个变量呀

回退代码修改，删除了所有的_pycache_文件夹，增加检测代码：

![image-20251006160724821](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006160724821.png)

![屏幕截图 2025-10-06 160627](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-10-06%20160627.png)

直接爆炸了，没招了。

回退，尝试改成evaluation_vqvae_motionmillion_1gpu试试

![image-20251006171823568](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006171823568.png)

还是![image-20251006171845238](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006171845238.png)
```python
0it [00:00, ?it/s]batch is None, Continue
1it [03:23, 203.00s/it]
Backend TkAgg is interactive backend. Turning interactive mode on.
Traceback (most recent call last):
  File "c:\Users\WINDOWS\.cursor\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy\_vendored\pydevd\pydevd.py", line 3717, in <module>
    main()
  File "c:\Users\WINDOWS\.cursor\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy\_vendored\pydevd\pydevd.py", line 3702, in main
    globals = debugger.run(setup["file"], None, None, is_module)
  File "c:\Users\WINDOWS\.cursor\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy\_vendored\pydevd\pydevd.py", line 2698, in run
    return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)
  File "c:\Users\WINDOWS\.cursor\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy\_vendored\pydevd\pydevd.py", line 2706, in _exec
    globals = pydevd_runpy.run_path(file, globals, "__main__")
  File "c:\Users\WINDOWS\.cursor\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy\_vendored\pydevd\_pydevd_bundle\pydevd_runpy.py", line 310, in run_path
    return _run_module_code(code, init_globals, run_name, pkg_name=pkg_name, script_name=fname)
  File "c:\Users\WINDOWS\.cursor\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy\_vendored\pydevd\_pydevd_bundle\pydevd_runpy.py", line 127, in _run_module_code
    _run_code(code, mod_globals, init_globals, mod_name, mod_spec, pkg_name, script_name)
  File "c:\Users\WINDOWS\.cursor\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy\_vendored\pydevd\_pydevd_bundle\pydevd_runpy.py", line 118, in _run_code
    exec(code, run_globals)
  File "train_tokenizer.py", line 311, in <module>
    main()
  File "train_tokenizer.py", line 236, in main
    best_mpjpe, writer, logger = eval_trans.evaluation_vqvae_motionmillion_1gpu(args.out_dir, train_loader, val_loader, net, logger, writer, 0, best_fid=1000, best_iter=0, best_div=100, best_top1=0, best_top2=0, best_top3=0, best_matching=100, best_mpjpe=1000, comp_device=comp_device, draw=True, save=True, savegif=False, savenpy=False, fps=60, cal_acceleration=False)
  File "d:\Programme\Python\Anaconda3lenvs\motionmillion\lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "D:\Desktop\动画项目\MotionMillion-Codes\utils\eval_trans.py", line 258, in evaluation_vqvae_motionmillion_1gpu
    for batch in tqdm(val_loader):
  File "d:\Programme\Python\Anaconda3lenvs\motionmillion\lib\site-packages\tqdm\std.py", line 1181, in __iter__
    for obj in iterable:
  File "d:\Programme\Python\Anaconda3lenvs\motionmillion\lib\site-packages\accelerate\data_loader.py", line 559, in __iter__
    current_batch = send_to_device(current_batch, self.device, non_blocking=self._non_blocking)
UnboundLocalError: local variable 'current_batch' referenced before assignment
Traceback (most recent call last):
  File "d:\Programme\Python\Anaconda3lenvs\motionmillion\lib\runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "d:\Programme\Python\Anaconda3lenvs\motionmillion\lib\runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "c:\Users\WINDOWS\.cursor\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy\__main__.py", line 71, in <module>
    cli.main()
  File "c:\Users\WINDOWS\.cursor\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy/..\debugpy\server\cli.py", line 501, in main
    run()
  File "c:\Users\WINDOWS\.cursor\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy/..\debugpy\server\cli.py", line 384, in run_module
    run_module_as_main(options.target, alter_argv=True)
  File "c:\Users\WINDOWS\.cursor\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy\_vendored\pydevd\_pydevd_bundle\pydevd_runpy.py", line 228, in _run_module_as_main
    return _run_code(code, main_globals, None, "__main__", mod_spec)
  File "c:\Users\WINDOWS\.cursor\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy\_vendored\pydevd\_pydevd_bundle\pydevd_runpy.py", line 118, in _run_code
    exec(code, run_globals)
  File "d:\Programme\Python\Anaconda3lenvs\motionmillion\lib\site-packages\accelerate\commands\launch.py", line 1178, in <module>
    main()
  File "d:\Programme\Python\Anaconda3lenvs\motionmillion\lib\site-packages\accelerate\commands\launch.py", line 1174, in main
    launch_command(args)
  File "d:\Programme\Python\Anaconda3lenvs\motionmillion\lib\site-packages\accelerate\commands\launch.py", line 1168, in launch_command
    simple_launcher(args)
  File "d:\Programme\Python\Anaconda3lenvs\motionmillion\lib\site-packages\accelerate\commands\launch.py", line 763, in simple_launcher
    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)
subprocess.CalledProcessError: Command '['d:\\Programme\\Python\\Anaconda3lenvs\\motionmillion\\python.exe', 'train_tokenizer.py', '--batch-size', '2', '--lr', '1e-4', '--total-iter', '200', '--lr-scheduler', '100', '--down-t', '1', '--depth', '2', '--dilation-growth-rate', '2', '--out-dir', 'results/output/debug_mini', '--dataname', 'motionmillion', '--vq-act', 'relu', '--quantizer', 'ema_reset', '--loss-vel', '0.5', '--recons-loss', 'l1_smooth', '--exp-name', 'debug_mini_200samples', '--quantizer', 'FSQ', '--nb-code', '1024', '--motion_type', 'vector_272', '--version', 'version1/tokenizer_96', '--warm-up-iter', '40', '--num-workers', '24', '--window-size', '32', '--kernel-size', '3', '--use_patcher', '--patch_size', '1', '--patch_method', 'haar', '--vq-norm', 'LN']' returned non-zero exit status 1. 
PS D:\Desktop\动画项目\MotionMillion-Codes> 
```