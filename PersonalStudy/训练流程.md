### MotionMillion项目训练代码流程

### 原始数据集下载（一部分就行）

[InternRobotics/MotionMillion at main](https://huggingface.co/datasets/InternRobotics/MotionMillion/tree/main)

split.tar.gz、texts.tar.gz、mean_std、motion_272rpr的MotionLLAMA的一部分数据

![image-20250930120604150](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930120604150.png)

![image-20250930120900241](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930120900241.png)

#### 1. 数据处理流程

![image-20250930121236900](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930121236900.png)

![image-20250930121626338](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930121626338.png)

似乎是训练时自动调用的，需要研读

#### 2. 训练流程

目录结构：

![image-20250930120929470](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930120929470.png)

执行训练：

![image-20250930114936605](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930114936605.png)





1. 熟悉这些数据格式（后面需要用这些数据训练我们的PFNN模型,到时候我会让你将数据处理成pfnn的格式）
2. Train Tokenizer(学习他如何利用FSQ对动作编码的，你需要理解并给我讲清楚FSQ的好处，为啥不用VQ-VAE，是你自己的想法，因为他们可能只是为了凑个新的点作为自己的创新点)
3. Train Text-to-Motion model这部分你跑一遍理解一下基于transformer的decoder是怎么运作的
4. 然后你需要对每个数据集的动作类型，处理代码了解清楚，如果他是将不同格式的数据都处理成motionMillion的data representation的话





### 我做了什么：

#### 问题：

![image-20250930184028037](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930184028037.png)

![image-20250930184131755](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930184131755.png)

文件里包含了太多没有下载下来的文件，都修改了一下，只保留MotionGV/folder0/开头的文件





#### 问题：

![image-20250930182934259](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930182934259.png)

![image-20250930185914707](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930185914707.png)

![image-20250930185947597](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930185947597.png)

![image-20250930190036525](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930190036525.png)

![image-20250930190046495](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930190046495.png)





跑着跑着内存就炸了，可能必须得上服务器了

![image-20250930195637901](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930195637901.png)

后续：怀疑是split删改的锅，但是还原后还是出现了内存爆炸的情况，可能确实跑不了？

![image-20250930221533887](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20250930221533887.png)





### 10/1：任务：

修改脚本获取train tokenizer VQVAE的具体参数

train_tokenizer.py里面会有VQVAE的初始化代码（120行开始net = vqvae.HumanVQVAE(args,...）
然后等它初始化完，调用torch的接口print这个模型参数的大小（trainable parameter的数量）

```python
import torch
import torch.nn as nn

# 假设你有一个模型
model = nn.Sequential(
    nn.Linear(100, 50),
    nn.ReLU(),
    nn.Linear(50, 10)
)

# 方法1.1: 打印每个参数的形状和大小
for name, param in model.named_parameters():
    print(f"{name}: {param.shape} | 参数数量: {param.numel()}")

# 输出:
# 0.weight: torch.Size([50, 100]) | 参数数量: 5000
# 0.bias: torch.Size([50]) | 参数数量: 50
# 2.weight: torch.Size([10, 50]) | 参数数量: 500
# 2.bias: torch.Size([10]) | 参数数量: 10
# 方法1.2: 计算总参数数量
total_params = sum(p.numel() for p in model.parameters())
print(f"总参数量: {total_params:,}")  # 输出: 总参数量: 5,560

# 方法1.3: 计算可训练参数数量（通常与总参数相同，除非冻结了某些层）
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"可训练参数量: {trainable_params:,}")
```

![image-20251002172532530](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251002172532530.png)

输出结果：

```
2025-10-02 17:23:54,728 INFO ==================================================
2025-10-02 17:23:54,728 INFO HumanVQVAE 模型参数信息:
2025-10-02 17:23:54,728 INFO ==================================================
2025-10-02 17:23:54,728 INFO vqvae.encoder.model.1.weight: torch.Size([512, 272, 3]) | 参数数量: 417,792
2025-10-02 17:23:54,728 INFO vqvae.encoder.model.1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.0.weight: torch.Size([512, 512, 4]) | 参数数量: 1,048,576
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.0.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.norm1.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.norm1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.norm2.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.norm2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.conv1.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.conv1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,729 INFO vqvae.encoder.model.3.1.model.0.conv2.weight: torch.Size([512, 512, 1]) | 参数数量: 262,144
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.0.conv2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.norm1.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.norm1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.norm2.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.norm2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.conv1.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.conv1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,730 INFO vqvae.encoder.model.3.1.model.1.conv2.weight: torch.Size([512, 512, 1]) | 参数数量: 262,144
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.1.conv2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.2.norm1.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.2.norm1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.2.norm2.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.2.norm2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.2.conv1.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,731 INFO vqvae.encoder.model.3.1.model.2.conv1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,732 INFO vqvae.encoder.model.3.1.model.2.conv2.weight: torch.Size([512, 512, 1]) | 参数数量: 262,144
2025-10-02 17:23:54,732 INFO vqvae.encoder.model.3.1.model.2.conv2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,732 INFO vqvae.encoder.model.4.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,732 INFO vqvae.encoder.model.4.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,732 INFO vqvae.decoder.model.0.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,732 INFO vqvae.decoder.model.0.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,732 INFO vqvae.decoder.model.2.0.model.0.norm1.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.norm1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.norm2.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.norm2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.conv1.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.conv1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.conv2.weight: torch.Size([512, 512, 1]) | 参数数量: 262,144
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.0.conv2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.1.norm1.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,733 INFO vqvae.decoder.model.2.0.model.1.norm1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.1.norm2.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.1.norm2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.1.conv1.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.1.conv1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.1.conv2.weight: torch.Size([512, 512, 1]) | 参数数量: 262,144
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.1.conv2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.2.norm1.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,734 INFO vqvae.decoder.model.2.0.model.2.norm1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.0.model.2.norm2.weight: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.0.model.2.norm2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.0.model.2.conv1.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.0.model.2.conv1.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.0.model.2.conv2.weight: torch.Size([512, 512, 1]) | 参数数量: 262,144
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.0.model.2.conv2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.2.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.2.2.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.3.weight: torch.Size([512, 512, 3]) | 参数数量: 786,432
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.3.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.5.weight: torch.Size([272, 512, 3]) | 参数数量: 417,792
2025-10-02 17:23:54,735 INFO vqvae.decoder.model.5.bias: torch.Size([272]) | 参数数量: 272
2025-10-02 17:23:54,735 INFO vqvae.quantizer.project_in.weight: torch.Size([6, 512]) | 参数数量: 3,072
2025-10-02 17:23:54,736 INFO vqvae.quantizer.project_in.bias: torch.Size([6]) | 参数数量: 6
2025-10-02 17:23:54,736 INFO vqvae.quantizer.project_out.weight: torch.Size([512, 6]) | 参数数量: 3,072
2025-10-02 17:23:54,736 INFO vqvae.quantizer.project_out.bias: torch.Size([512]) | 参数数量: 512
2025-10-02 17:23:54,736 INFO ==================================================
2025-10-02 17:23:54,736 INFO 总参数量: 11,349,782
2025-10-02 17:23:54,736 INFO 可训练参数量: 11,349,782
2025-10-02 17:23:54,736 INFO ==================================================
2025-10-02 17:23:54,736 INFO 模型参数统计完成，程序结束
```

![image-20251002175911948](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251002175911948.png)

![image-20251002175929632](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251002175929632.png)





### 10/2：继续定位：

问题似乎出在这里，需要进一步看看到底是在做什么：

![image-20251002180828538](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251002180828538.png)

其中一个问题（内存分配问题）应该是手部模型的锅，这里应该用不到，想办法取消掉





### 10/3-4，定位问题，修改参数：

![image-20251005233810119](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005233810119.png)

warm_up部分能跑完了。



### 10/5：训练部分：

修改了训练参数之后warm_up部分没问题了，但还是训练会出现

![屏幕截图 2025-10-05 232509](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202025-10-05%20232509.png)

#### 尝试一：

在AI的建议下尝试修改代码：

![image-20251005234318581](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005234318581.png)

![image-20251005234232541](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005234232541.png)

![image-20251005234241711](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005234241711.png)

![image-20251005234259295](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005234259295.png)

![image-20251005234310590](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005234310590.png)

出现了这样的问题：

![image-20251005234843224](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005234843224.png)

撤回了更改



#### 尝试二：

![image-20251005235217821](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005235217821.png)

![image-20251006000005432](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006000005432.png)

![image-20251005235907786](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251005235907786.png)

还是先撤回问问老师吧





10/6：

注释了可视化相关的代码，还是出现了问题：![image-20251006145731863](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006145731863.png)

![image-20251006145758974](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006145758974.png)

![image-20251006145811726](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006145811726.png)

![image-20251006145820774](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006145820774.png)



新的问题接踵而至：

![image-20251006153533449](%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B.assets/image-20251006153533449.png)

问题是压根就没有current_batch这个变量呀？

是Util缓存的问题，但是原来的代码没有current_batch这个变量呀
